/*
 * -------------------------------------------------
 *  nf-core/cleansumstats Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

// Set todays date, used to create dated files/folders
today = new Date().format("yyyy-MM-dd-HHmm")

// work dir (scratch is emptied after finished run, so can't be combined with intermediate files)
// manually switch to scratch for production version
//workDir = "/scratch/${USER}-${today}-nf-workdir"
//tmpDir = "/scratch/${USER}-${today}-nf-tmpdir"
workDir = "work"
tmpDir = "tmp"

// Global default params, used in configs
params {

  //pipeline root
  libdir = '/home/projects/ip_10000/IBP_pipelines/cleansumstats/cleansumstats_dev'

  // Surveillance folders
  outdir = './results'
  results = "${params.outdir}"

  // Images images

  // Result folders special flags
  libdirreference = "${params.libdir}/sumstat_reference"

  // Reference folders
  libdirdbsnp = "${params.libdir}/sumstat_reference/dbsnp151/new"
  dbsnp_38 = "${params.libdirdbsnp}/All_20180418_GRCh38.sorted.bed"
  dbsnp_38_37 = "${params.libdirdbsnp}/All_20180418_GRCh38_GRCh37.sorted.bed"
  dbsnp_37_38 = "${params.libdirdbsnp}/All_20180418_GRCh37_GRCh38.sorted.bed"
  dbsnp_36_38 = "${params.libdirdbsnp}/All_20180418_GRCh36_GRCh38.sorted.bed"
  dbsnp_35_38 = "${params.libdirdbsnp}/All_20180418_GRCh35_GRCh38.sorted.bed"
  dbsnp_RSID_38 = "${params.libdirdbsnp}/All_20180418_RSID_GRCh38.sorted.bed"
  libdir1kaf = "${params.libdir}/sumstat_reference/1kg_allele_frequency"
  kg1000AFGRCh38 = "${params.libdir1kaf}/1kg_af_ref.sorted"


  // Filters
  beforeLiftoverFilter = "duplicated_keys"
  afterLiftoverFilter = "duplicated_chrpos_refalt_in_GRCh38,multiple_rsids_in_dbsnp"
  afterAlleleCorrectionFilter = ""

  //auxiallary functionality
  generateMetafile = false
  generateDbSNPreference = false
  generate1KgAfSNPreference = false

  //auxiallary functionality required files
  hg38ToHg19chain = "${params.libdir}/sumstat_reference/liftover_chains/hg38ToHg19.over.chain.gz"
  hg19ToHg18chain = "${params.libdir}/sumstat_reference/liftover_chains/hg19ToHg18.over.chain.gz"
  hg19ToHg17chain = "${params.libdir}/sumstat_reference/liftover_chains/hg19ToHg17.over.chain.gz"

  // Boilerplate options
  name = false
  multiqc_config = "$baseDir/assets/multiqc_config.yaml"
  email = false
  email_on_fail = false
  maxMultiqcEmailFileSize = 25.MB
  plaintext_email = false
  monochrome_logs = false
  help = false
  igenomes_base = "./iGenomes"
  tracedir = "${params.results}/pipeline_info"
  awsqueue = false
  awsregion = 'eu-west-1'
  igenomesIgnore = false
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames = false
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false
}

// Container slug. Stable releases should specify release tag!
// Developmental code should specify :dev

////set this again when submitting to nfcore (now unset to make own singularity images work)
//process.container = 'nfcore/cleansumstats:dev'

////replace inline singularity calls using this (important to add all software used in process in image)
//process {
//    withName:infer_stats {
//        container = '/home/people/jesgaa/images/from-own/2020-04-11-ubuntu-1804_stat_r_in_c.simg'
//    }
//}
//singularity {
//    enabled = true
//}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

profiles {
  awsbatch { includeConfig 'conf/awsbatch.config' }
  conda { process.conda = "$baseDir/environment.yml" }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker { docker.enabled = true }
  singularity { singularity.enabled = true }
  test { includeConfig 'conf/test.config' }
}

// Avoid this error:
// WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
// Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351, once this is established and works well, nextflow might implement this behavior as new default.
docker.runOptions = '-u \$(id -u):\$(id -g)'

// Load igenomes.config if required
if (!params.igenomesIgnore) {
  includeConfig 'conf/igenomes.config'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

manifest {
  name = 'nf-core/cleansumstats'
  author = 'Jesper R. GÃ¥din'
  homePage = 'https://github.com/nf-core/cleansumstats'
  description = 'convert GWAS sumstat files into a common format with a common reference for positions, rsids and effect alleles.'
  mainScript = 'main.nf'
  nextflowVersion = '>=0.32.0'
  version = '1.0dev'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
