/*
 * -------------------------------------------------
 *  nf-core/cleansumstats Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

 //use scratch for default settings (not active solution.  Right now better to use workDir and tmpDir arguments and point them to scratch)
//env.SCRATCH='/scratch/${USER}-nf-workdir'
//env.TMPDIR='$SCRATCH'
//env.NXF_WORK='$SCRATCH'
//process.scratch = true

//today=$(date +%Y-%m-%d)
//today = new java.util.Date()
//Date newDate = Date()
//String today = date.format( 'yyyy-M-dd' )
//println new Date().format("yyyy-MM-dd HH.mm.ss.SSSSS Z")
today = new Date().format("yyyy-MM-dd-HHmm")

workDir = "/scratch//${USER}-${today}-nf-workdir"
tmpDir = "/scratch/${USER}-${today}-nf-tmpdir"

// Set this to false if debugging (as it cleans the workdir)
// The folders will still conntinue to exist in scratch but all will empty
cleanup = true

// Global default params, used in configs
params {

  //library root
  libdir = '/home/projects/ip_10000/IBP_pipelines/cleansumstats/cleansumstats_dev'

  // Surveillance folders
  outdir = './results'
  results = "${params.outdir}"

  // Result folders
  libdirsumstats = "${params.libdir}/sumstat_library"
  libdirpdfs = "${params.libdir}/sumstat_pdfs"
  libdirinventory = "${params.libdir}/sumstat_inventory"
  libdirreference = "${params.libdir}/sumstat_reference"

  libdirdbsnp = "${params.libdir}/sumstat_reference/dbsnp151/new"


  // Reference folders
  dbsnp_38 = "${params.libdirdbsnp}/All_20180418_GRCh38.sorted.bed"
  dbsnp_38_37 = "${params.libdirdbsnp}/All_20180418_GRCh38_GRCh37.sorted.bed"
  dbsnp_37_38 = "${params.libdirdbsnp}/All_20180418_GRCh37_GRCh38.sorted.bed"
  dbsnp_36_38 = "${params.libdirdbsnp}/All_20180418_GRCh36_GRCh38.sorted.bed"
  dbsnp_35_38 = "${params.libdirdbsnp}/All_20180418_GRCh35_GRCh38.sorted.bed"
  dbsnp_RSID_38 = "${params.libdirdbsnp}/All_20180418_RSID_GRCh38.sorted.bed"

  // Filters
  beforeLiftoverFilter = "duplicated_keys"
  afterLiftoverFilter = "duplicated_chrpos_refalt_in_GRCh38,duplicated_chrpos_in_GRCh38,multiallelics_in_dbsnp"
  afterAlleleCorrectionFilter = "duplicated_chrpos_in_GRCh38"

  //auxiallary functionality
  generateMetafile = false

  generateDbSNPreference = false

  hg38ToHg19chain = "${params.libdir}/sumstat_reference/liftover_chains/hg38ToHg19.over.chain.gz"
  hg19ToHg18chain = "${params.libdir}/sumstat_reference/liftover_chains/hg19ToHg18.over.chain.gz"
  hg19ToHg17chain = "${params.libdir}/sumstat_reference/liftover_chains/hg19ToHg17.over.chain.gz"
  // hg38ToHg19chain = "/home/people/jesgaa/data/dbsnp151/data/hg38ToHg19.over.chain.gz"
  // hg19ToHg18chain = "/home/people/jesgaa/data/dbsnp151/data/hg19ToHg18.over.chain.gz"
  // hg19ToHg17chain = "/home/people/jesgaa/data/dbsnp151/data/hg19ToHg17.over.chain.gz"

  checkerOnly = false

  // Control output
  keepIntermediateFiles = false

  // Boilerplate options
  name = false
  multiqc_config = "$baseDir/assets/multiqc_config.yaml"
  email = false
  email_on_fail = false
  maxMultiqcEmailFileSize = 25.MB
  plaintext_email = false
  monochrome_logs = false
  help = false
  igenomes_base = "./iGenomes"
  tracedir = "${params.results}/pipeline_info"
  awsqueue = false
  awsregion = 'eu-west-1'
  igenomesIgnore = false
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames = false
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false
}

// Container slug. Stable releases should specify release tag!
// Developmental code should specify :dev

////set this again when submitting to nfcore (now unset to make own singularity images work)
//process.container = 'nfcore/cleansumstats:dev'

////replace inline singularity calls using this (important to add all software used in process in image)
//process {
//    withName:infer_stats {
//        container = '/home/people/jesgaa/images/from-own/2020-04-11-ubuntu-1804_stat_r_in_c.simg'
//    }
//}
//singularity {
//    enabled = true
//}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

profiles {
  awsbatch { includeConfig 'conf/awsbatch.config' }
  conda { process.conda = "$baseDir/environment.yml" }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker { docker.enabled = true }
  singularity { singularity.enabled = true }
  test { includeConfig 'conf/test.config' }
}

// Avoid this error:
// WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
// Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351, once this is established and works well, nextflow might implement this behavior as new default.
docker.runOptions = '-u \$(id -u):\$(id -g)'

// Load igenomes.config if required
if (!params.igenomesIgnore) {
  includeConfig 'conf/igenomes.config'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

manifest {
  name = 'nf-core/cleansumstats'
  author = 'Jesper R. GÃ¥din'
  homePage = 'https://github.com/nf-core/cleansumstats'
  description = 'convert GWAS sumstat files into a common format with a common reference for positions, rsids and effect alleles.'
  mainScript = 'main.nf'
  nextflowVersion = '>=0.32.0'
  version = '1.0dev'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
